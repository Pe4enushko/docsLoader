# Как работает приложение (простое объяснение)

## Коротко
Это сервис внутреннего контроля качества медприёма.
Он проверяет, насколько корректно врач заполнил данные приёма, используя клинические рекомендации из базы знаний (knowledge graph) по коду МКБ.

## Что загружается в систему заранее
Перед проверками в систему один раз загружаются PDF с клиническими рекомендациями.

Что делает загрузка:
1. Читает PDF по страницам.
2. Делит документ на разделы.
3. Делит текст на смысловые куски (chunks).
4. Строит embeddings для поиска по смыслу.
5. Сохраняет всё в локальный Weaviate.

Для этого используется скрипт:
- `init_knowledge_graph.py`

## Что приходит на вход при проверке
На вход приходит JSON из API с данными приёма.
Например: жалобы, анамнез, осмотр, диагноз, рекомендации, динамика и т.д.

Скрипт проверки:
- `validate_appointment_pipeline.py`

## Что происходит во время проверки
1. Приложение берёт входной JSON целиком.
2. По коду МКБ (`DOC_ID_OR_MKB_CODE`) ищет релевантные фрагменты рекомендаций в Weaviate.
3. Собирает компактный контекст (несколько лучших фрагментов).
4. Передаёт в LLM:
   - весь входной JSON,
   - найденные фрагменты рекомендаций.
5. LLM возвращает строго структурированный результат (через `with_structured_output` + Pydantic).

## Что возвращает система
Итоговый JSON с оценками качества заполнения приёма:

- `overall_score` (1-5)
- `risk_level` (`low | medium | high`)
- `score_visit_identification` (1-5)
- `score_anamnesis` (1-5)
- `score_inspection` (1-5)
- `score_dynamic` (1-5)
- `score_diagnosis` (1-5)
- `score_recommendations` (1-5)
- `score_structure` (1-5)
- `issues` (все замечания строкой, разделитель `;`)
- `summary` (1-3 строки для главного врача)

## Главный рабочий скрипт
Для основной логики проверки вердикта:
- `docsToGraphRAG.py`

(Он работает в режиме judge-only.)

## Логи
Логи пишутся одновременно:
- в терминал,
- в файл `logs/*.log`.

В логах есть:
- шаги поиска в Weaviate,
- действия загрузки/чтения,
- ошибки,
- ответ LLM в сокращённом виде (чтобы не засорять вывод).

## Что нужно настроить один раз
Файл `.env`:
- `WEAVIATE_URL` — адрес локального Weaviate
- `OLLAMA_EMBED_BASE_URL` — Ollama для embeddings
- `OLLAMA_CHAT_BASE_URL` — Ollama для judge-модели
- `OLLAMA_EMBED_MODEL`
- `OLLAMA_CHAT_MODEL`

## Типичный рабочий цикл
1. Обновили/добавили PDF рекомендаций.
2. Запустили `init_knowledge_graph.py`.
3. Сервис получил JSON приёма из API.
4. Запустили `validate_appointment_pipeline.py`.
5. Получили структурированный итоговый JSON для контроля качества.
